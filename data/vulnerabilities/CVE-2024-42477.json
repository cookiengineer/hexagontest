{
	"name": "CVE-2024-42477",
	"description": "llama.cpp provides LLM inference in C/C++. The unsafe 'type' member in the 'rpc_tensor' structure can cause 'global-buffer-overflow'. This vulnerability may lead to memory data leakage. The vulnerability is fixed in b3561.",
	"type": "none",
	"severity": "none",
	"state": "published",
	"references": [
		"https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b",
		"https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-mqp6-7pv6-fqjf"
	],
	"datetime": "2025-02-06 12:35:15",
	"connections": [],
	"devices": [],
	"distributions": [],
	"packages": [],
	"products": [
		{
			"name": "ggerganov:llamacpp",
			"vendor": "ggerganov",
			"product": "llamacpp",
			"version": "\u003c b3561",
			"type": "software"
		}
	],
	"programs": [],
	"weaknesses": [
		{
			"name": "CWE-401",
			"impact": "any",
			"scope": "any"
		},
		{
			"name": "CWE-125",
			"impact": "any",
			"scope": "any"
		}
	]
}